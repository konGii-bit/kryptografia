{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216947c2-36b5-4777-94a3-e9604eb42e44",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe z wykorzystaniem szyfrowania homomorficznego\n",
    "### Autorzy: Marcin Szwed, Konrad Meling, Patryk Twardowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51838797",
   "metadata": {},
   "source": [
    "### Wprowadzenie do biblioteki TenSEAL\n",
    "\n",
    "https://github.com/OpenMined/TenSEAL/tree/main\n",
    "\n",
    "TenSEAL to biblioteka do homomorficznego szyfrowania danych w Pythonie. Umożliwia wykonywanie operacji arytmetycznych na zaszyfrowanych danych, z zachowaniem ich poufności. Zbudowana jest na bazie biblioteki Microsoft SEAL, zapewniając wysokopoziomowe API przy zachowaniu wydajności operacji.\n",
    "\n",
    "Microsoft SEAL, na której bazuje TenSEAL, to biblioteka C++ rozwijana przez Cryptography Research Group firmy Microsoft. Umożliwia generowanie kluczy, szyfrowanie i deszyfrowanie przy użyciu popularnych schematów homomorficznych, takich jak CKKS (dla danych zmiennoprzecinkowych) oraz BFV (dla liczb całkowitych). Użycie SEAL wymaga znajomości zagadnień kryptograficznych i zarządzania pamięcią, co czyni TenSEAL wygodnym, uproszczonym interfejsem dla użytkowników Pythona.\n",
    "\n",
    "TenSEAL upraszcza procedurę szyfrowania, udostępniając wygodne API z niższym progiem wejścia. Biblioteka pozwala na enkrypcję i dekrypcję używając BFV i CKKS.\n",
    "\n",
    "Podstawowe funkcjonalności:\n",
    "- dodawanie: sum_inplace, sum_batch_inplace\n",
    "- mnożenie macierzy: matmul_inplace, matmul_plain_inplace\n",
    "- iloczyn skalarny: dot, dot_inplace\n",
    "- potęgowanie: power_inplace\n",
    "- negacja: negate_inplace\n",
    "\n",
    "TenSEAL wspiera także operacje na tensorach a także konwolucję, jest kompatybilna z biblioteką TensorFlow i PyTorch co sprawia że można jej używać w zastosowanych zadaniach dotyczących sieci neuronowych. \n",
    "\n",
    "Ze względu na zastosowanie operacji homomorficznych, nie jest możliwe obliczanie funkcji nieliniowych, takich jak sigmoid, a co za tym idzie stosujemy przybliżenia wielomianowe, np:\n",
    "\n",
    "sigmoid(x) ≈ 0.5 + 0.197·x − 0.004·x³\n",
    "\n",
    "### Krótkie przedstawienie możliwości biblioteki\n",
    "\n",
    "Tworzymy kontekst CKKS dla szyfrowania homomorficznego, używając następujących parametrów:\n",
    " - poly_modulus_degree - stopień wielomianu pierścieniowego, wpłwa na bezpieczeństwo i czas wykonywania operacji\n",
    " - coeff_mod_bit_size - wskazuje poziomy redukcji szumu podczas szyfrowania, ilość modułów określa możliwe operacje mnożenia - w naszy przypadku 3\n",
    " - global_scale - globalny współczynnik skalujący. Ckks używa go do kontrolowania precyzji liczb zmiennoprzecinkowych, im wyższa wartość tym większa dokładność, ale istnieje ryzyko błędu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240a3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, \n",
    "                    poly_modulus_degree=8192, \n",
    "                    coeff_mod_bit_sizes=[60, 40, 40, 60] )\n",
    "context.global_scale = 2**40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85878168",
   "metadata": {},
   "source": [
    "Generujemy klucze Galois, potrzebne do rotacji wektorów zaszyfrowanych w homomorficznym szyfrowaniu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c90e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c56f0",
   "metadata": {},
   "source": [
    "Przeprowadzamy proste testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd2d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wektor 1: [0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "wektor 2: [1, 2, 3, 4, 5] \n",
      "\n",
      "dekrypcja wektora 1: [0.10000000018142119, 0.2000000018217, 0.2999999995825561, 0.4000000008859689, 0.4999999997796727] \n",
      "\n",
      "wynik dodawania wektora zakodowanego i jawnego: [1.1000000001771122, 2.2000000018433807, 3.2999999996024583, 4.4000000008897455, 5.499999999776742]\n",
      "wynik dodawania dwóch wektorów zakodowanych: [1.1000000010466078, 2.2000000030882014, 3.3000000002861603, 4.400000000935252, 5.500000000324521] \n",
      "\n",
      "wynik odejmowania wektora zakodowanego i jawnego: [-0.89999999981427, -1.7999999981999804, -2.7000000004373463, -3.5999999991178075, -4.500000000217398]\n",
      "wynik odejmowania dwóch wektorów zakodowanych: [-0.9000000006837658, -1.7999999994448008, -2.7000000011210483, -3.5999999991633143, -4.500000000765176]\n",
      "\n",
      "[0.10000001355017132, 0.40000005152148, 0.9000001190189988, 1.6000002176984236, 2.5000003319328745]\n",
      "wynik mnożenia wektora zakodowanego przez jawny: [0.10000001355017132, 0.40000005152148, 0.9000001190189988, 1.6000002176984236, 2.5000003319328745]\n",
      "wynik mnożenia dwóch wektorów zakodowanych: [0.10000001345548803, 0.40000005783191295, 0.9000001193364714, 1.6000002184895774, 2.500000334156014]\n"
     ]
    }
   ],
   "source": [
    "vector1 = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "vector2 = [1, 2, 3, 4, 5]\n",
    "print(f\"wektor 1: {vector1}\")\n",
    "print(f\"wektor 2: {vector2} \\n\")\n",
    "encrypted_vector1 = ts.ckks_vector(context, vector1)\n",
    "encrypted_vector2 = ts.ckks_vector(context, vector2)\n",
    "\n",
    "decrypted_vector = encrypted_vector1.decrypt()\n",
    "print(f\"dekrypcja wektora 1: {decrypted_vector} \\n\")\n",
    "\n",
    "add_result = encrypted_vector1 + [1, 2, 3, 4, 5]\n",
    "print(f\"wynik dodawania wektora zakodowanego i jawnego: {add_result.decrypt()}\") \n",
    "\n",
    "encrypted_sum = encrypted_vector1 + encrypted_vector2\n",
    "print(f\"wynik dodawania dwóch wektorów zakodowanych: {encrypted_sum.decrypt()} \\n\") \n",
    "\n",
    "sub_result = encrypted_vector1 - [1, 2, 3, 4, 5]\n",
    "print(f\"wynik odejmowania wektora zakodowanego i jawnego: {sub_result.decrypt()}\") \n",
    "\n",
    "encrypted_diff = encrypted_vector1 - encrypted_vector2\n",
    "print(f\"wynik odejmowania dwóch wektorów zakodowanych: {encrypted_diff.decrypt()}\\n\") \n",
    "\n",
    "mul_result = encrypted_vector1 * [1, 2, 3, 4, 5]\n",
    "print(mul_result.decrypt())  \n",
    "print(f\"wynik mnożenia wektora zakodowanego przez jawny: {mul_result.decrypt()}\") \n",
    "\n",
    "encrypted_product = encrypted_vector1 * encrypted_vector2\n",
    "print(f\"wynik mnożenia dwóch wektorów zakodowanych: {encrypted_product.decrypt()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f1a3a",
   "metadata": {},
   "source": [
    "Przykładowa estymacja funkcji sigmoid(x) wielomianem trzeciego stopnia dla zakodowanego wektora. Z racji iż mamy do czynienia z wielomianem trzeciego stopnia, czyli kilkoma mnożeniami, następuje widoczna utrata dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e4db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid dla wektora jawnego: [0.52497919 0.549834   0.57444252 0.59868766 0.62245933]\n",
      "sigmoid dla wektora zakodowanego: [0.5196960021808914, 0.5393680061507066, 0.5589920080900813, 0.5785440112288189, 0.5980000120385917]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "result = encrypted_vector1.polyval([0.5, 0.197, 0, -0.004])\n",
    "\n",
    "y = expit(vector1)\n",
    "\n",
    "print(f\"sigmoid dla wektora jawnego: {y}\")\n",
    "print(f\"sigmoid dla wektora zakodowanego: {result.decrypt()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9769d785",
   "metadata": {},
   "source": [
    "TenSEAL wspiera także:\n",
    " - serializację i deserializację obiektów (save, load)\n",
    " - operacje im2col dla konwolucji\n",
    " - szyfrowane mnożenie macierz-wektor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8a285-be08-4778-952b-96a9374e578b",
   "metadata": {},
   "source": [
    "## Przegląd algorytmów\n",
    "* regresja liniowa, metody gradientowe - stosunkowo proste, wyłącznie mnożenie i dodawanie\n",
    "* pełna liniowa regresja - jeżeli serwer zgromadziłby wszystkie dane od klientów konieczne jest odwracanie macierzy\n",
    "* regresja z użyciem prostych sieci neuronowych np. z jedną warstwą ukrytą - teoretycznie możliwa, ale zawyczaj stosowane są nieliniowe funkcje aktywacji jak ReLU\n",
    "* regresja logistyczna - przy wyznaczaniu prawdopodobieństwa jest stosowana funkcja sigmoidalna, którą można w pewnym zakresie wartości aproksymować wielomianem\n",
    "* klasyfikacja naiwną metodą Bayesa - wymaga funkcji log(), chyba, że mały wymiar, bo wtedy można pomnożyć prawdopodobieństwa\n",
    "* klasyfikacja metodą najbliższysch sąsiadów KNN - teoretycznie można obliczać w zaszyfrowany sposób odległość, ale musiałaby być porównywana po stronie klienta więc raczej bez sensu\n",
    "* drzewa decyzyjne - wymagają porównań\n",
    "* klasyfikacja z siecią neuronową - wymaga exp() w ostatniej warstwie, bo sigmoid albo softmax jest funkcją aktywacji ostatniej warstwy, funkcja celu zawiera zazwyczaj logarytm (cross entropy)\n",
    "\n",
    "## Przypadki użycia\n",
    "\n",
    "Scenariusz, w którym serwer przechowuje model niezaszyfrowany.\n",
    "\n",
    "* Klient przesyła do serwera zaszyfrowane dane oraz klucz publiczny\n",
    "* Serwer szyfruje nim model\n",
    "* Serwer przeprowadza predykcję używając zaszyfrowanych parametrów modelu i zaszyfrowanych danych\n",
    "* Serwer zwraca wyniki predykcji\n",
    "* Klient odszyfrowuje wyniki predykcji posługując się kluczem prywatnym\n",
    "\n",
    "Scenariusz, w którym serwer otrzymuje zaszyfrowane dane i trenuje model z zaszyfrowanymi parametrami.\n",
    "\n",
    "* Klient wysyła zaszyfrowane dane i klucz publiczny do serwera, przesyła także informacje o danych typu rozmiar danych i liczba rekordów\n",
    "* Serwer inicjuje model i szyfruje go\n",
    "* Następnie w pętli serwer wykonuje kolejne kroki uczenia, podczas których wyznacza funkcję straty, jej gradient względem wag, a następnie uaktualnia wagi\n",
    "* Po zakończeniu treningu przesyła do klienta zaszyfrowane wagi lub cały zaszyfrowany model\n",
    "* Klient odszyfrowuje wyniki, może ocenić jakość modelu i użyć go do predykcji na własnych danych\n",
    "\n",
    "\n",
    "\n",
    "## Poniższy przykład\n",
    "* klient ma parametry modelu i dane\n",
    "* klient przesyła zaszyfrowane parametry modelu i dane do serwera\n",
    "* serwer oblicza błąd i zwraca do klienta\n",
    "* klient uaktualnia model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae762c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 1, MSE (HE): 0.51257\n",
      "Epoka 2, MSE (HE): 0.49286\n",
      "Epoka 3, MSE (HE): 0.47592\n",
      "Epoka 4, MSE (HE): 0.46118\n",
      "Epoka 5, MSE (HE): 0.44824\n",
      "Epoka 6, MSE (HE): 0.43677\n",
      "Epoka 7, MSE (HE): 0.42657\n",
      "Epoka 8, MSE (HE): 0.41743\n",
      "Epoka 9, MSE (HE): 0.40922\n",
      "Epoka 10, MSE (HE): 0.40182\n",
      "MSE modelu HE:  0.4018181815793052\n",
      "MSE modelu sklearn:  0.324313493798384\n",
      "Wagi HE: [-0.14735328 -0.06858322  0.17461548]\n",
      "Wagi sklearn:  [-0.32609907 -0.13320203  0.55650174]\n",
      "Bias HE:  -0.09468727161194786\n",
      "Bias sklearn:  -0.13157153183388606\n"
     ]
    }
   ],
   "source": [
    "import tenseal as ts\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = load_diabetes()\n",
    "X = data.data[:, :3]  \n",
    "y = data.target\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "X_train = X[:20]\n",
    "y_train = y[:20]\n",
    "\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    ")\n",
    "context.global_scale = 2 ** 40\n",
    "context.generate_galois_keys()\n",
    "\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "w = np.zeros(n_features)\n",
    "b = 0.0\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "\n",
    "#Trening: klient-serwer\n",
    "for epoch in range(epochs):\n",
    "    grad_w = np.zeros(n_features)\n",
    "    grad_b = 0.0\n",
    "\n",
    "    # klient szyfruje parametry\n",
    "    w_enc = ts.ckks_vector(context, w.tolist())\n",
    "    b_enc = ts.ckks_vector(context, [b])\n",
    "\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        x_i = X_train[i]\n",
    "        y_i = y_train[i]\n",
    "        # klient szyfruje dane\n",
    "        x_enc = ts.ckks_vector(context, x_i.tolist())\n",
    "        y_enc = ts.ckks_vector(context, [y_i])\n",
    "\n",
    "        # Tu oblicza serwer\n",
    "        pred_enc = x_enc.dot(w_enc) + b_enc\n",
    "\n",
    "        error_enc = pred_enc - y_enc\n",
    "\n",
    "        # serwer wysyła do klienta\n",
    "        error = error_enc.decrypt()[0]\n",
    "\n",
    "        grad_w += error * x_i\n",
    "        grad_b += error\n",
    "\n",
    "    grad_w /= len(X_train)\n",
    "    grad_b /= len(X_train)\n",
    "\n",
    "    w -= learning_rate * grad_w\n",
    "    b -= learning_rate * grad_b\n",
    "\n",
    "    y_pred = X_train.dot(w) + b\n",
    "    mse = mean_squared_error(y_train, y_pred)\n",
    "    print(f\"Epoka {epoch+1}, MSE (HE): {mse:.5f}\")\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_train)\n",
    "mse_lr = mean_squared_error(y_train, y_pred_lr)\n",
    "\n",
    "print(\"MSE modelu HE: \", mean_squared_error(y_train, X_train.dot(w) + b))\n",
    "print(\"MSE modelu sklearn: \", mse_lr)\n",
    "print(\"Wagi HE:\", w)\n",
    "print(\"Wagi sklearn: \", lr.coef_)\n",
    "print(\"Bias HE: \", b)\n",
    "print(\"Bias sklearn: \", lr.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
