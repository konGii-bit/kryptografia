{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216947c2-36b5-4777-94a3-e9604eb42e44",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe z wykorzystaniem szyfrowania homomorficznego\n",
    "### Autorzy: Marcin Szwed, Konrad Meling, Patryk Twardowski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8a285-be08-4778-952b-96a9374e578b",
   "metadata": {},
   "source": [
    "## Przegląd algorytmów\n",
    "* regresja liniowa, metody gradientowe - stosunkowo proste, wyłącznie mnożenie i dodawanie\n",
    "* pełna liniowa regresja - jeżeli serwer zgromadziłby wszystkie dane od klientów konieczne jest odwracanie macierzy\n",
    "* regresja z użyciem prostych sieci neuronowych np. z jedną warstwą ukrytą - teoretycznie możliwa, ale zawyczaj stosowane są nieliniowe funkcje aktywacji jak ReLU\n",
    "* regresja logistyczna - odpada, bo exp()\n",
    "* klasyfikacja naiwną metodą Bayesa - odpada, bo log(), chyba, że mały wymiar, bo wtedy można pomnożyć prawdopodobieństwa\n",
    "* klasyfikacja metodą najbliższysch sąsiadów KNN - teoretycznie można obliczać w zaszyfrowany sposób odległość, ale musiałaby być porównywana po stronie klienta więc raczej bez sensu\n",
    "* drzewa decyzyjne - wymagają porównań\n",
    "* klasyfikacja z siecią neuronową - wymaga exp() w ostatniej warstwie, bo sigmoid albo softmax jest funkcją aktywacji ostatniej warstwy, funkcja celu zawiera zazwyczaj logarytm (cross entropy)\n",
    "\n",
    "Właściwie zostaje regresja liniowa. W przypadku sieci neuronowych trzeba by stosować wielomianowe aproksymacje rozmaitych funkcji co jest teoretycznie możliwe.\n",
    "\n",
    "\n",
    "## Organizacja uczenia\n",
    "Przypadek A:\n",
    "* jeden klient, jeden serwer\n",
    "* klient szyfruje dane i model lokalnie i przesyła do serwera\n",
    "* serwer wykonuje uczenie i zwraca klientowi metryki uczenia\n",
    "* jeżeli klient chce dokonać predykcji to szyfruje dane, wysyła do serwera i dostaje rezultaty\n",
    "\n",
    "Przypadek B:\n",
    "* kilku niezależnych klientów ma swoje dane, którymi nie chce się dzielić\n",
    "* jeden serwer przyjmuje zakodowane dane i używa ich do uczenia modelu\n",
    "* model (wagi) jest zakodowany i przechowywany w takiej formie przez serwer\n",
    "* na żądanie przez klienta serwer może wyznaczyć zaszyfrowaną predykcję dla zaszyfrowanych danych\n",
    "* klient odkoduje predykcję\n",
    "\n",
    "Problem: Trzeba ustalić kto ma jakie klucze, np. klucz publiczny ma serwer i klienci, klucze prywatne mają tylko klienci, klucz Galois i relinearyzacji ma serwer.\n",
    "\n",
    "## Poniższy przykład\n",
    "* klient ma parametry modelu i dane\n",
    "* klient przesyła zaszyfrowane parametry modelu i dane do serwera\n",
    "* serwer oblicza błąd i zwraca do klienta\n",
    "* klient uaktualnia model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae762c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 1, MSE (HE): 0.51257\n",
      "Epoka 2, MSE (HE): 0.49286\n",
      "Epoka 3, MSE (HE): 0.47592\n",
      "Epoka 4, MSE (HE): 0.46118\n",
      "Epoka 5, MSE (HE): 0.44824\n",
      "Epoka 6, MSE (HE): 0.43677\n",
      "Epoka 7, MSE (HE): 0.42657\n",
      "Epoka 8, MSE (HE): 0.41743\n",
      "Epoka 9, MSE (HE): 0.40922\n",
      "Epoka 10, MSE (HE): 0.40182\n",
      "MSE modelu HE:  0.4018181815793052\n",
      "MSE modelu sklearn:  0.324313493798384\n",
      "Wagi HE: [-0.14735328 -0.06858322  0.17461548]\n",
      "Wagi sklearn:  [-0.32609907 -0.13320203  0.55650174]\n",
      "Bias HE:  -0.09468727161194786\n",
      "Bias sklearn:  -0.13157153183388606\n"
     ]
    }
   ],
   "source": [
    "import tenseal as ts\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = load_diabetes()\n",
    "X = data.data[:, :3]  \n",
    "y = data.target\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "X_train = X[:20]\n",
    "y_train = y[:20]\n",
    "\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    ")\n",
    "context.global_scale = 2 ** 40\n",
    "context.generate_galois_keys()\n",
    "\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "w = np.zeros(n_features)\n",
    "b = 0.0\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "\n",
    "#Trening: klient-serwer\n",
    "for epoch in range(epochs):\n",
    "    grad_w = np.zeros(n_features)\n",
    "    grad_b = 0.0\n",
    "\n",
    "    # klient szyfruje parametry\n",
    "    w_enc = ts.ckks_vector(context, w.tolist())\n",
    "    b_enc = ts.ckks_vector(context, [b])\n",
    "\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        x_i = X_train[i]\n",
    "        y_i = y_train[i]\n",
    "        # klient szyfruje dane\n",
    "        x_enc = ts.ckks_vector(context, x_i.tolist())\n",
    "        y_enc = ts.ckks_vector(context, [y_i])\n",
    "\n",
    "        # Tu oblicza serwer\n",
    "        pred_enc = x_enc.dot(w_enc) + b_enc\n",
    "\n",
    "        error_enc = pred_enc - y_enc\n",
    "\n",
    "        # serwer wysyła do klienta\n",
    "        error = error_enc.decrypt()[0]\n",
    "\n",
    "        grad_w += error * x_i\n",
    "        grad_b += error\n",
    "\n",
    "    grad_w /= len(X_train)\n",
    "    grad_b /= len(X_train)\n",
    "\n",
    "    w -= learning_rate * grad_w\n",
    "    b -= learning_rate * grad_b\n",
    "\n",
    "    y_pred = X_train.dot(w) + b\n",
    "    mse = mean_squared_error(y_train, y_pred)\n",
    "    print(f\"Epoka {epoch+1}, MSE (HE): {mse:.5f}\")\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_train)\n",
    "mse_lr = mean_squared_error(y_train, y_pred_lr)\n",
    "\n",
    "print(\"MSE modelu HE: \", mean_squared_error(y_train, X_train.dot(w) + b))\n",
    "print(\"MSE modelu sklearn: \", mse_lr)\n",
    "print(\"Wagi HE:\", w)\n",
    "print(\"Wagi sklearn: \", lr.coef_)\n",
    "print(\"Bias HE: \", b)\n",
    "print(\"Bias sklearn: \", lr.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
